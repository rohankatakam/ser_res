{
    "execution": "019c0c19-9fab-7b66-af1d-10015041f6b2",
    "output": {
        "result": {
            "chapters": {
                "assembly_request_id": "220a223f-9d25-4054-9742-99e73aaca5ea",
                "assembly_response": "```json\n[\n  {\n    \"title\": \"Introduction and AI Research Process\",\n    \"order\": 1,\n    \"description\": \"How Gavin processes new AI developments like Gemini 3, the importance of using paid tiers, and following key researchers on X\",\n    \"start_time\": \"00:00:00\",\n    \"end_time\": \"00:08:30\"\n  },\n  {\n    \"title\": \"Scaling Laws and Gemini 3 Significance\",\n    \"order\": 2,\n    \"description\": \"Understanding pre-training scaling laws, the empirical nature of these observations, and why Gemini 3 was important for confirming they remain intact\",\n    \"start_time\": \"00:08:30\",\n    \"end_time\": \"00:15:45\"\n  },\n  {\n    \"title\": \"The Blackwell Delay and Reasoning Models\",\n    \"order\": 3,\n    \"description\": \"How Blackwell's complex product transition was delayed and how reasoning models bridged the gap, preventing AI progress from stalling\",\n    \"start_time\": \"00:15:45\",\n    \"end_time\": \"00:25:20\"\n  },\n  {\n    \"title\": \"Google's Temporary Advantage and Cost Dynamics\",\n    \"order\": 4,\n    \"description\": \"Google's position as low-cost token producer with advanced TPUs and their strategy of 'sucking economic oxygen' from competitors\",\n    \"start_time\": \"00:25:20\",\n    \"end_time\": \"00:35:10\"\n  },\n  {\n    \"title\": \"The Coming Blackwell Era and Competitive Shifts\",\n    \"order\": 5,\n    \"description\": \"XAI's expected first Blackwell model, the GB300's drop-in compatibility, and how this changes the competitive landscape\",\n    \"start_time\": \"00:35:10\",\n    \"end_time\": \"00:45:30\"\n  },\n  {\n    \"title\": \"TPU vs GPU Architecture Battle\",\n    \"order\": 6,\n    \"description\": \"Google's conservative design choices, the Broadcom partnership economics, and why TPUs are falling behind in the accelerating GPU roadmap\",\n    \"start_time\": \"00:45:30\",\n    \"end_time\": \"00:58:15\"\n  },\n  {\n    \"title\": \"The Human Dividend of AI Infrastructure\",\n    \"order\": 7,\n    \"description\": \"What all this infrastructure development enables - from personal assistants to customer support automation and the ROI question\",\n    \"start_time\": \"00:58:15\",\n    \"end_time\": \"01:08:45\"\n  },\n  {\n    \"title\": \"Bear Cases and Edge AI Concerns\",\n    \"order\": 8,\n    \"description\": \"Potential threats to cloud AI demand, including edge AI capabilities and the risk of 'good enough' on-device models\",\n    \"start_time\": \"01:08:45\",\n    \"end_time\": \"01:18:20\"\n  },\n  {\n    \"title\": \"From Intelligence to Usefulness\",\n    \"order\": 9,\n    \"description\": \"The S-curve progression of AI models and the need to transition from raw intelligence gains to practical utility and consistency\",\n    \"start_time\": \"01:18:20\",\n    \"end_time\": \"01:28:30\"\n  },\n  {\n    \"title\": \"Enterprise AI Adoption and ROI Evidence\",\n    \"order\": 10,\n    \"description\": \"Fortune 500 companies beginning to show quantitative AI benefits, with C.H. Robinson as a key example of revenue impact\",\n    \"start_time\": \"01:28:30\",\n    \"end_time\": \"01:38:45\"\n  },\n  {\n    \"title\": \"Frontier Model Dynamics and Barriers to Entry\",\n    \"order\": 11,\n    \"description\": \"How reasoning models create flywheels, why Meta and Microsoft failed to build competitive models, and the four leading labs\",\n    \"start_time\": \"01:38:45\",\n    \"end_time\": \"01:52:30\"\n  },\n  {\n    \"title\": \"China's Strategic Mistake and Geopolitical Implications\",\n    \"order\": 12,\n    \"description\": \"China's rare earth strategy backfiring as Blackwell widens the gap with Chinese AI capabilities\",\n    \"start_time\": \"01:52:30\",\n    \"end_time\": \"02:02:15\"\n  },\n  {\n    \"title\": \"Data Centers in Space - The Ultimate Infrastructure\",\n    \"order\": 13,\n    \"description\": \"Why space-based data centers are superior from first principles - unlimited solar power, free cooling, and faster networking\",\n    \"start_time\": \"02:02:15\",\n    \"end_time\": \"02:15:45\"\n  },\n  {\n    \"title\": \"Power Constraints and Natural Governors\",\n    \"order\": 14,\n    \"description\": \"How power limitations benefit advanced compute players and the solutions through natural gas and solar power\",\n    \"start_time\": \"02:15:45\",\n    \"end_time\": \"02:25:20\"\n  },\n  {\n    \"title\": \"AI-Native Entrepreneurs and Semiconductor VC Renaissance\",\n    \"order\": 15,\n    \"description\": \"The impressive capabilities of young AI-native founders and how Nvidia's success has reignited semiconductor venture investing\",\n    \"start_time\": \"02:25:20\",\n    \"end_time\": \"02:35:40\"\n  },\n  {\n    \"title\": \"SaaS Companies' Critical Mistake\",\n    \"order\": 16,\n    \"description\": \"How SaaS companies are repeating brick-and-mortar retailers' e-commerce mistakes by refusing to accept AI's lower gross margins\",\n    \"start_time\": \"02:35:40\",\n    \"end_time\": \"02:45:55\"\n  },\n  {\n    \"title\": \"Rolling Bubbles and Market Observations\",\n    \"order\": 17,\n    \"description\": \"Current bubbles in nuclear and quantum stocks, and the strange phenomenon of AI getting whatever it needs to continue growing\",\n    \"start_time\": \"02:45:55\",\n    \"end_time\": \"02:53:30\"\n  },\n  {\n    \"title\": \"Atreides Evolution and Investment Philosophy\",\n    \"order\": 18,\n    \"description\": \"How Gavin's firm has evolved to balance conviction with flexibility and create a culture where being wrong is safe and celebrated\",\n    \"start_time\": \"02:53:30\",\n    \"end_time\": \"03:02:45\"\n  },\n  {\n    \"title\": \"Gavin's Origin Story - From Ski Bum to Investor\",\n    \"order\": 19,\n    \"description\": \"The complete story of how a planned life as a ski bum and wildlife photographer transformed into a passion for investing through one internship\",\n    \"start_time\": \"03:02:45\",\n    \"end_time\": \"03:15:00\"\n  }\n]\n```",
                "assembly_usage_data": {
                    "input_tokens": 24040,
                    "output_tokens": 1708
                },
                "id": "asmb-220a223f-9d25-4054-9742-99e73aaca5ea",
                "podcast_episode_id": "gavin-baker-nvid-56vg8t-j397bp",
                "podcast_episode_name": "Gavin Baker - Nvidia v. Google, Scaling Laws, and the Economics of AI - [Invest Like the Best, EP.451]",
                "podcast_series_name": "Invest Like the Best with Patrick O'Shaughnessy",
                "question_source": "system",
                "question_text": "Provide a list of chapters of this episode in JSON format. Each chapter should have the following fields: title, order, description, start_time and end_time. The \"order\" should be a number starting from 1 and incrementing by 1 for each chapter. The \"description\" should be a concise but meaningful addition to the \"title\". The \"start_time\" and \"end_time\" are the timestamps the chapter starts and ends at.\n",
                "question_timestamp": "2025-12-09T11:07:10.870995+00:00",
                "question_type": "chapters"
            },
            "data_points": {
                "assembly_request_id": "a12582d4-c5ef-475c-9ce1-535a61c2e60d",
                "assembly_response": "Based on this interview with Gavin Baker, here are the top 5 specific quantitative metrics and data points:\n\n1. AI Expense Processing Efficiency\n- Ramp's AI handles 85% of expense reviews automatically with 99% accuracy\n- This represents a dramatic shift from manual finance work to automated processing\n\n2. GPU Cluster Scaling and Coherence Limits\n- Maximum coherent GPU cluster size: ~200,000 Hopper GPUs\n- Target for next generation: 200,000-300,000 Blackwell GPUs maximum (due to physics constraints)\n- Coherence means each GPU can communicate with every other GPU during training\n\n3. Data Center Power Requirements Evolution\n- Hopper generation: ~30 kilowatts per rack (equivalent to 30 American homes)\n- Blackwell generation: ~130 kilowatts per rack (equivalent to 130 American homes)\n- Weight increase: From ~1,000 pounds to ~3,000 pounds per rack\n- This represents a 4.3x increase in power density\n\n4. Space-Based Data Center Energy Advantage\n- 6x more solar irradiance available in space vs. Earth\n- 30% more intense sunlight in space\n- 24/7 solar exposure (no night cycle) eliminates need for batteries\n\n5. Customer Support AI Adoption Rate\n- 50%+ of customer support at tech-forward companies is already AI-powered\n- $400 billion total addressable market for customer support industry\n- This demonstrates real-world AI deployment at scale beyond just experimental use cases\n\nThese metrics illustrate the massive infrastructure scaling happening in AI, the physical constraints being reached, and the quantifiable business impact already occurring across industries.",
                "assembly_usage_data": {
                    "input_tokens": 23971,
                    "output_tokens": 411
                },
                "id": "asmb-a12582d4-c5ef-475c-9ce1-535a61c2e60d",
                "podcast_episode_id": "gavin-baker-nvid-56vg8t-j397bp",
                "podcast_episode_name": "Gavin Baker - Nvidia v. Google, Scaling Laws, and the Economics of AI - [Invest Like the Best, EP.451]",
                "podcast_series_name": "Invest Like the Best with Patrick O'Shaughnessy",
                "question_source": "system",
                "question_text": "Please provide the top 3 to 5 specific metrics or data points from this  interview. The goal is to improve my knowledge through important quantifiable,  numeric insights. Focus on being as clear, specific and quantified as possible.\n",
                "question_timestamp": "2025-12-09T11:07:10.871068+00:00",
                "question_type": "data_points"
            },
            "insights": {
                "assembly_request_id": "2853e31d-55e7-4270-923a-ec1ffc276bfb",
                "assembly_response": "Here are the top 3 key takeaways from this interview with Gavin Baker:\n\n1. The Infrastructure War Between Nvidia and Google Will Reshape AI Economics\n\nBaker explains that Google currently holds a temporary advantage as the \"low cost producer of tokens\" using their TPU V6 and V7 chips, while Nvidia's Blackwell chips faced significant deployment delays due to complexity (requiring liquid cooling, 3x rack weight, and 4x power consumption). However, this dynamic is about to flip dramatically. When Blackwell models launch in early 2026 (likely from XAI first), followed by the drop-in compatible GB300 chips, Nvidia-powered companies will become the low-cost producers.\n\nWhy this matters: This shift will force Google to abandon their current strategy of running AI at negative 30% margins to \"suck the economic oxygen out of the ecosystem.\" As Baker notes, it's rational for a low-cost producer to operate at a loss to squeeze competitors, but painful for a high-cost producer. This transition will fundamentally alter the competitive landscape and economics of AI, potentially benefiting companies like OpenAI, Anthropic, and XAI while pressuring Google's market position.\n\n2. Three Scaling Laws Are Driving AI Progress, Creating Multiplicative Effects\n\nBaker clarifies a crucial misunderstanding about AI progress. While pre-training scaling laws (the original foundation) should have stalled in 2024-2025 due to chip constraints, two new scaling laws emerged: reinforcement learning with verified rewards (post-training) and test-time compute. These allowed dramatic progress (like Arc AGI scores jumping from 8% to 95% in three months) during what should have been a stagnant period.\n\nWhy this matters: Gemini 3's release confirmed that pre-training scaling laws remain intact, meaning all three scaling laws are now multiplicative. As Baker explains, \"now we're going to apply these two new reinforcement learning with verified rewards and test time compute to much better base models.\" This creates a compounding effect that will accelerate AI capabilities significantly, especially as cheaper inference costs allow models to \"think\" much longer on problems.\n\n3. Data Centers in Space Represent the Next Frontier for AI Infrastructure\n\nBaker presents a compelling first-principles argument for space-based data centers: space offers 6x more solar irradiance than Earth (sun 24/7, 30% more intense, no batteries needed), free cooling via radiators facing absolute zero, and faster networking through laser communication in vacuum versus fiber optics. The user experience would be superior - direct satellite-to-phone communication versus the current multi-hop path through cell towers and terrestrial data centers.\n\nWhy this matters: This isn't science fiction speculation but an inevitable economic optimization that requires SpaceX's Starship for feasible launch costs. Baker sees this as part of the convergence between Elon Musk's companies - XAI provides intelligence, Tesla builds robots with vision systems, and SpaceX enables space-based compute infrastructure. While training will initially remain Earth-based due to scale requirements, inference could migrate to space within 5-6 years, fundamentally changing the economics of AI deployment and potentially solving power constraints that currently limit AI growth.",
                "assembly_usage_data": {
                    "input_tokens": 23984,
                    "output_tokens": 714
                },
                "id": "asmb-2853e31d-55e7-4270-923a-ec1ffc276bfb",
                "podcast_episode_id": "gavin-baker-nvid-56vg8t-j397bp",
                "podcast_episode_name": "Gavin Baker - Nvidia v. Google, Scaling Laws, and the Economics of AI - [Invest Like the Best, EP.451]",
                "podcast_series_name": "Invest Like the Best with Patrick O'Shaughnessy",
                "question_source": "system",
                "question_text": "Please provide the top 3 key takeaways from this interview. Provide specificity  and details for each insight, along with the motivation for why it's relevant. Be clear, direct and concise, but feel free to elaborate when explaining a complex idea or nuance is required.\n",
                "question_timestamp": "2025-12-09T11:07:10.871016+00:00",
                "question_type": "insights"
            },
            "new_ideas": {
                "assembly_request_id": "d7154f7a-b700-497d-b0b5-02b3caea3bd8",
                "assembly_response": "This episode contains several genuinely contrarian insights that challenge conventional wisdom in AI and technology investing.\n\nTop 3 Contrarian Insights:\n\n1. Data Centers in Space as the Inevitable Future of AI Infrastructure\nThis is perhaps the most contrarian view in the episode. Baker argues that from first principles, data centers should be in space because: solar energy is 6x more intense, cooling is free via radiators facing absolute zero, and laser communication between satellites is faster than fiber optic cables. He predicts this will happen within 3-4 years as SpaceX scales Starship production. This directly contradicts the massive terrestrial data center buildout currently underway and challenges fundamental assumptions about AI infrastructure location.\n\n2. Google's Temporary Advantage Will Reverse, Creating Strategic Upheaval\nBaker contends that Google currently has a decisive cost advantage in AI token production due to their TPU technology, which explains their strategy of \"sucking the economic oxygen out of the AI ecosystem\" by running AI at negative margins. However, he predicts this advantage will flip when Nvidia's Blackwell and subsequent chips become widely deployed, forcing Google to abandon their aggressive pricing strategy. This contradicts the common view that Google's integrated approach gives them a permanent structural advantage.\n\n3. SaaS Companies Are Making a Fatal Strategic Error by Preserving High Margins\nBaker argues that established SaaS companies are repeating the mistake of brick-and-mortar retailers who refused to embrace e-commerce due to margin concerns. He believes SaaS companies must accept 40% gross margins for AI products instead of their traditional 80%+ margins, or risk being displaced entirely. As he puts it: \"If you are trying to preserve an 80% gross margin structure, you are guaranteeing that you will not succeed in AI. Absolute guarantee.\" This challenges the widespread investor and management focus on maintaining high SaaS margins.\n\nOverall Assessment: Highly Non-Consensus\n\nThis episode is highly non-consensus in its core technological and strategic predictions. Baker presents detailed, first-principles reasoning for views that directly contradict current market behavior and conventional wisdom. His space-based data center thesis alone represents thinking that's years ahead of mainstream consideration. The technical depth around chip architectures, scaling laws, and competitive dynamics shows sophisticated contrarian analysis rather than surface-level hot takes. While some observations about AI progress align with general optimism in the field, the specific predictions about competitive positioning and infrastructure evolution are genuinely differentiated from consensus views.",
                "assembly_usage_data": {
                    "input_tokens": 24136,
                    "output_tokens": 545
                },
                "id": "asmb-d7154f7a-b700-497d-b0b5-02b3caea3bd8",
                "podcast_episode_id": "gavin-baker-nvid-56vg8t-j397bp",
                "podcast_episode_name": "Gavin Baker - Nvidia v. Google, Scaling Laws, and the Economics of AI - [Invest Like the Best, EP.451]",
                "podcast_series_name": "Invest Like the Best with Patrick O'Shaughnessy",
                "question_source": "system",
                "question_text": "Please analyze this conversation to identify contrarian insights: ideas that are truly non-obvious or opinions that meaningfully differ from the consensus in business, technology, investing, or society. Identify up to 3 of the most contrarian or non-consensus ideas. For each insight, briefly explain why it is contrarian or reflects highly original thinking. If there is a quote in the transcript that significantly enhances the clarity or impact of the insight, you may include it in your response. If no strongly contrarian or differentiated views are present, please say so and just highlight the single most original idea.\nProvide an overall assessment of how contrarian the episode was. Use terms such as “highly non-consensus,” “somewhat insightful,” or “aligned with commonly held views,” and briefly explain your reasoning. Be clear, specific, concise, and objective, but feel free to elaborate when nuance is required. Maintain a very high bar for what qualifies as contrarian or non-obvious, and do not stretch commonly held views.\n",
                "question_timestamp": "2025-12-09T11:07:10.871030+00:00",
                "question_type": "new_ideas"
            },
            "summary": {
                "assembly_request_id": "e17958c7-0ab7-49a8-b094-1a1e4ebb5dee",
                "assembly_response": "## Episode Overview\n\nThis episode features Patrick O'Shaughnessy, CEO of Positive Sum, interviewing Gavin Baker, founder of Atreides Management. Baker is a veteran technology investor with over 15 years of fund management experience who has become one of the most knowledgeable voices on AI infrastructure and semiconductor investing.\n\n## Key Discussion Points\n\n### AI Model Development and Testing Process\n\nBaker emphasizes the importance of hands-on testing when evaluating new AI models like Gemini 3. He criticizes investors who make definitive conclusions about AI capabilities based on free tiers, comparing it to \"dealing with a 10-year-old and making conclusions about the 10-year-old's capabilities as an adult.\" He advocates paying for the highest tiers ($200/month) to properly evaluate models and following the 500-1,000 cutting-edge AI researchers on X (Twitter) for real-time insights.\n\n### Scaling Laws and Model Progress\n\nBaker explains that Gemini 3 was crucial because it confirmed that scaling laws for pre-training remain intact, despite no one understanding why they work. He compares our understanding to \"ancient British people's understanding of the sun\" - perfect measurement without comprehending the underlying mechanics. The progress in 2024-2025 came not from pre-training scaling laws but from two new scaling laws: reinforcement learning with verified rewards and test-time compute.\n\n### The Nvidia vs. Google Infrastructure Battle\n\nA central theme is the ongoing competition between Nvidia's GPUs and Google's TPUs. Baker details how Blackwell's complexity created an 18-month delay that could have stalled AI progress entirely, but reasoning models \"saved AI\" by bridging this gap. Key technical details:\n\n- Blackwell transition required moving from air-cooled to liquid-cooled systems\n- Rack weight increased from ~1,000 to 3,000 pounds\n- Power consumption jumped from 30 kilowatts to 130 kilowatts per rack\n- Google gained temporary advantage using TPU V6 and V7 chips during Blackwell delays\n\n### Cost Dynamics and Strategic Implications\n\nBaker argues that being the low-cost producer matters for the first time in tech history. Google has been \"sucking the economic oxygen out of the AI ecosystem\" by running AI at potentially -30% margins. However, this calculus changes when Blackwell models deploy and Google loses its cost advantage. He predicts XAI will have the first Blackwell model in early 2026 because \"no one builds data centers faster than Elon.\"\n\n### Data Centers in Space\n\nBaker presents a compelling case for space-based data centers as inevitable:\n- 6x more solar irradiance in space vs. Earth\n- No need for batteries (24/7 sunlight)\n- Free cooling via radiators on satellite dark side\n- Faster networking through laser communication in vacuum\n- Direct-to-cell communication eliminates terrestrial infrastructure\n\nHe estimates this requires \"a lot of Starships\" but represents the logical endpoint of data center evolution.\n\n### Economic Returns and Market Dynamics\n\nBaker addresses ROI concerns by pointing to audited financials showing that major GPU spenders have higher return on invested capital than before their AI spending ramp. He notes constant internal battles at tech companies between revenue teams wanting more GPUs and research teams, with revenue teams arguing \"if you give me more GPUs, I will drive more revenue.\"\n\n### SaaS Industry Transformation\n\nBaker draws parallels between current SaaS companies and brick-and-mortar retailers' response to e-commerce. He argues SaaS companies are making a \"fundamental mistake\" by refusing to accept AI's lower gross margins (40% vs. 80%), guaranteeing they'll lose to AI-native competitors. He specifically calls out that Microsoft is the only major SaaS company successfully navigating this transition.\n\n### Semiconductor Venture Capital Renaissance\n\nThe success of Nvidia has \"single-handedly ignited semiconductor venture\" with a unique dynamic - the average semiconductor venture founder is 50 years old, bringing decades of expertise. Baker notes that Nvidia needs thousands of components in each Blackwell rack, requiring an entire ecosystem to accelerate together.\n\n### Investment Philosophy Evolution\n\nBaker shares his evolution from a \"one-man show\" to building a team culture that makes it \"safe for people to change their mind\" and \"extremely safe telling me that I'm wrong.\" He emphasizes that \"if you were not wrong, you're not learning\" and structures \"bull bear lunches\" where analysts present opposing cases.\n\n### Personal Origin Story\n\nThe episode concludes with Baker's unexpected path into investing - originally planning to be a ski bum, river guide, and wildlife photographer before a mandatory internship at Donaldson Lufkin Jenrette sparked his passion for investing as \"the greatest game of skill and chance imaginable.\"\n\n## Notable Data Points\n\n- 85% of expense reviews automated by AI with 99% accuracy\n- XAI processing 1.35 trillion tokens vs. Google's 800-900 billion on OpenRouter\n- 50% of Fortune 500 customer support already done by AI in tech-forward companies\n- C.H. Robinson improved quote response from 60% to 100% of requests, reducing time from 15-45 minutes to seconds\n- Broadcom earns 50-55% gross margins on TPU backend work, potentially $15 billion on estimated $30 billion TPU spending",
                "assembly_usage_data": {
                    "input_tokens": 23982,
                    "output_tokens": 1198
                },
                "id": "asmb-e17958c7-0ab7-49a8-b094-1a1e4ebb5dee",
                "podcast_episode_id": "gavin-baker-nvid-56vg8t-j397bp",
                "podcast_episode_name": "Gavin Baker - Nvidia v. Google, Scaling Laws, and the Economics of AI - [Invest Like the Best, EP.451]",
                "podcast_series_name": "Invest Like the Best with Patrick O'Shaughnessy",
                "question_source": "system",
                "question_text": "Provide a detailed summary of this episode. Preface the summary with a short description of who is speaking and featured in the episode, along with their backgrounds. Your summary should include specific data points and anecdotes to provide depth and specificity. Make the style direct and straight to the point.\n",
                "question_timestamp": "2025-12-09T11:07:10.870922+00:00",
                "question_type": "summary"
            },
            "top_quotes": {
                "assembly_request_id": "230a223f-9d25-4054-9742-99e73aaca5ea",
                "assembly_response": "Here are the top 5 most insightful quotes from this interview:\n\n1. On the fundamental nature of AI economics:\n\"AI is the first time in my career as a tech investor that being the low cost producer has ever mattered. Apple is not worth trillions because they're the low cost producer of phones. Microsoft is not worth trillions because they're the low cost producer of software. Nvidia is not worth trillions because they're the low cost producer of AI accelerators. It's never mattered.\"\n\n2. On the verification principle in AI:\n\"One of Karpathy's great things was with software, anything you can specify you can automate. With AI, anything you can verify you can automate. It's such an important concept and I think important distinction.\"\n\n3. On data centers in space from first principles:\n\"If you think about it from first principles, data centers should be in space. What are the fundamental inputs to running a data center? Power and cooling, and then the chips. In space, you can keep a satellite in the sun 24 hours a day, and the sun is 30% more intense... you're getting six times more irradiance in outer space than on planet Earth. For cooling, in space cooling is free. You just put a radiator on the dark side of the satellite.\"\n\n4. On the current state of scaling laws:\n\"No one on planet Earth knows how or why scaling laws for pre training work. It's actually not a law. It's an empirical observation... It's kind of like the ancient British people's understanding of the sun or the ancient Egyptians understanding the sun. They can measure it so precisely that the east west axis of the great pyramids are perfectly aligned with the equinoxes... Perfect measurement. They didn't understand orbital mechanics.\"\n\n5. On SaaS companies and AI adoption:\n\"Application SaaS companies are making the exact same mistake that brick and mortar retailers did with E Commerce... They have their 70, 80, 90% gross margins and they are reluctant to accept AI gross margins... If you are trying to preserve an 80% gross margin structure, you are guaranteeing that you will not succeed in AI. Absolute guarantee.\"",
                "assembly_usage_data": {
                    "input_tokens": 24000,
                    "output_tokens": 491
                },
                "id": "asmb-230a223f-9d25-4054-9742-99e73aaca5ea",
                "podcast_episode_id": "gavin-baker-nvid-56vg8t-j397bp",
                "podcast_episode_name": "Gavin Baker - Nvidia v. Google, Scaling Laws, and the Economics of AI - [Invest Like the Best, EP.451]",
                "podcast_series_name": "Invest Like the Best with Patrick O'Shaughnessy",
                "question_source": "system",
                "question_text": "Please provide the top 3 to 5 direct quotes from this interview that are  particularly insightful or profound. Each quote should be a standalone  thought or idea, not a question or comment. Focus on quotes that are grounded in specific data or evidence or convey a profound, interesting non-consensus view or sound uniquely wise, insightful and pithy.\n",
                "question_timestamp": "2025-12-09T11:07:10.871089+00:00",
                "question_type": "top_quotes"
            }
        }
    },
    "status": "STATUS_COMPLETED"
}